---
format: revealjs
---

# Today's Agenda {background-image="Images/background-data_blue_v4.png"}

```{r}
library(tidyverse)
library(readxl)
library(kableExtra)
library(modelsummary)
```

<br>

::: {.r-fit-text}

**Introduction to Univariate Analyses**

- Calculating and analyzing descriptive statistics

:::

<br>

::: r-stack
Justin Leinaweaver (Spring 2026)
:::

::: notes
Prep for Class

1. Check Canvas submissions

2. Reading: Pollock and Edwards (2026): Read Chapter 2, p39-58

<br>

**SLIDE**: Let's kick things off with our big picture motivations

:::



## What do we do with data? {background-image="Images/background-data_blue_v4.png" .center}

<br>

**Data as numbers...**

```{r, echo=FALSE}
set.seed(543)
d1 <- round(runif(125, 100, 250), 0)
d1
```

**Data as words or symbols...**

```{r, echo=FALSE}
d2 <- sample(x = c("low", "medium", "high"), size = 65, replace = TRUE)
d2f <- factor(d2, levels = c("low", "medium", "high"))
d2f
```

::: notes

The world is FULL of data and one of our big jobs this semester is to develop tools so you know what to do with it!

<br>

Over the next few weeks we will be focusing on univariate analyses

- e.g. the analysis of one variable on its own

- These are some of the most useful tools because they help you convert a big list of data points into something more useful!

<br>

**SLIDE**: The first key here is to realize that THIS is the problem statistics was invented to solve!
:::



# {background-image="Images/background-data_blue_v4.png"}

::: {.r-fit-text}
**Defining Statistics: Level 1**

Statistics offers tools we can use to summarize data
:::

<br>

**Find the "middle" of a series of numbers...**

```{r, echo=FALSE}
# Calculate the mean
mean(d1)
```

<br>

**Count the frequency of the words...**

```{r, echo=FALSE}
# Count the levels
table(d2)
```

::: notes

*READ SLIDE*

<br>

By summarize I mean to "give a brief statement of the main points of (something)" (Oxford Dictionary).

<br>

So, at its most basic level, statistics is about summary

- AND summary is incredibly useful for developing understanding about the world.

<br>

Rather than give someone a list of 500 numbers we can give them an average that tells us something about the middle of the distribution!

<br>

Rather than give someone a list of 500 words we can give them a frequency distribution so they can see how often each one is used

<br>

**SLIDE**: Statistics also carries with it some deeper ambitions!

:::


# {background-image="Images/background-data_blue_v4.png"}

::: {.r-fit-text}
**Defining Statistics: Level 2**

Statistics helps us draw inferences from sample to population
:::

<br>

![](Images/04_2-Inference.png){style="display: block; margin: 0 auto"}

::: notes

Statistics is also a collection of tools meant to help us with the process of inference

- Inference is a process by which we study something specific in order to learn something generalizable

<br>

In survey terms that means asking 1,500 Americans a question while intending to use that to represent the opinion of all Americans

<br>

In cross-national analyses, that's like gathering specific country-year data from the World Bank's WDI database but using it to learn about all countries and all years

<br>

**SLIDE**: Let's get set to do univariate analyses

:::



## {background-image="Images/background-data_blue_v4.png"}

:::{.r-fit-text}
**Create an R Script and name it "Descriptive Statistics.R"**
:::

- Option 1: "File" &#8594; "New File" &#8594; "R Script"

- Option 2:

![](Images/03_3-New_Script.png){.absolute bottom=0 left=200}


::: notes
Let's get off on the right foot!

- Create a new script file for your notes today and label it descriptive statistics.

- Make sure to save this file in your class folder

<br>

**SLIDE**: Identifying the tools of univariate analyses

:::



## {background-image="Images/background-data_blue_v4.png" .center}

Add the following to your notes:

```{r, echo=TRUE, eval=FALSE}
# Tools for describing a nominal variable:
# Frequency table (counts and/or proportions)

# Tools for describing an ordinal variable:
# Frequency table (counts, proportions and/or cumulative proportions)

# Tools for describing an interval-level variable:
# Mean
# Median
# Standard deviation
# The range (minimum to maximum)
# Percentiles
# The interquartile range (25th to 75th percentile)
```

::: notes

Write these down at the top of your R script file

- These are the tools we'll be learning to code today

- Use this like a checklist for yourself as we go

<br>

I think the textbook chapter does a good job introducing you to these tools and can serve as a reliable reference

- This way if you aren't understanding a concept, go back to the book!

- **Any big picture questions on these tools? e.g. how they attempt to summarize your data?**

<br>

I hope your takeaway from our work this week is to see that these tools of univariate analyses are INCREDIBLY powerful

- These are the concepts you need to BOTH summarize data and to generate inferences about the wider world

- EVERY complicated research project is built on a thorough univariate analysis

<br>

My plan for today is to use the Canvas assignment as a jumping off point into the code

- **SLIDE**: Let's start with Exercise 2

:::



## {background-image="Images/background-data_blue_v4.png" .center}

```{r}
d1 <- tibble(
  Value = c("Low egalitarianism", "Medium egalitarianism", "High egalitarianism"),
  Frequency = c(1121, 1133, 1359)
) |>
  mutate(
    Percentage = Frequency / sum(Frequency)*100,
    Cumulative = cumsum(Percentage)
  ) 

d1 |>
  kable(digits = 1, align = c("l", rep("c", 3))) |>
  kableExtra::kable_styling(font_size = 27)
```

<br>

:::: {.columns}
::: {.column width="50%"}
```{r, fig.align='center', fig.retina=3, fig.asp=1.1, out.width="70%", fig.width=6}
d1 |>
  ggplot(aes(y = Value, x = Percentage)) +
  geom_col(fill = "darkblue") +
  theme_bw() +
  labs(x = "Percentage", y = "") +
  scale_y_discrete(limits = c("Low egalitarianism", "Medium egalitarianism", "High egalitarianism"))
```
:::

::: {.column width="50%"}

<br>

- Modal value: "High"

- Median value: "Medium"

- Dispersion: Low (?)
:::
::::

::: notes

Exercise 2 gives us the chance to analyze an ordinal variable.

- **Did everybody get these results?**

<br>

- Modal: High egalitarianism is the most specified level

- Median: Medium egalitarianism is where the cumulative percentage crosses 50%

- Dispersion: I would call this low dispersion as these counts are very similar, but this is a fairly subjective call!

<br>

Basically when you are analyzing a nominal or ordinal variable these are the tools available to you:

- Count the levels, 

- Convert those counts into proportions of the whole,
    
- If Ordinal: Sum the proportions for cumulative totals,
    
- Identify the median and mode, and
    
- Describe the dispersion the variable

<br>

**Any questions on this exercise or the concepts being applied to analyze an ordinal variable?**

<br>

**SLIDE**: Let's now take these concepts into R

:::






##  {background-image="Images/background-data_blue_v4.png"}

![](Images/04_1-mpg_dataset.png){style="display: block; margin: 0 auto"}

<br>

```{r, echo=TRUE, eval=FALSE}
# Load the packages
library(tidyverse)

# List all of the variables in the dataset
names(mpg)

# Access one variable in the dataset with "$"
mpg$manufacturer
```

::: notes

R includes a number of built-in data sets for practice

- Each extra package tends to bring more practice data as well

<br>

The "mpg" data set is provided as part of an extra package.

-   "This dataset contains a subset of the fuel economy data that the EPA makes available on https://fueleconomy.gov/."

-   'mpg' has data on 234 cars (observations) across 11 variables

<br>

To access the dataset you have to load the tidyverse package in R with this code

- Everybody make sure to load tidyverse and then make sure you can access the mpg data

<br>

**Out of curiosity, is the manufacturer variable nominal or ordinal? Why?**

- (Nominal! No order to the levels)

<br>

**SLIDE**: Let's do univariate analysis on this nominal variable

:::



## {background-image="Images/background-data_blue_v4.png" .smaller}

::: {.r-fit-text}
**If you are analyzing a nominal variable:**
:::

<br>

```{r}
options(width = 90)
```

::: {.r-fit-text}

**1. Make a frequency table: table()**
```{r, echo=TRUE}
table(mpg$manufacturer)
```

**2. Convert to proportions: proportions()**
```{r, echo=TRUE}
proportions(table(mpg$manufacturer))
```
:::

::: notes

*Explain the code*

- The function, the dataset, the specific variable

- proportions() converts an already made table into a proportionate table

<br>

**Everybody got the code written down and working?**

<br>

Easy peasy, right?

- Copy this code into any project you need to, just update the data and variable

<br>

**SLIDE**: Moving to an ordinal variable adds one extra step you already did in the textbook exercises for today

:::



## {background-image="Images/background-data_blue_v4.png" .smaller}

::: {.r-fit-text}
**If you are analyzing an ordinal variable:**
:::

**1. Make a frequency table: table()**
```{r, echo=TRUE}
table(mpg$cyl)
```

**2. Convert to proportions: proportions()**
```{r, echo=TRUE}
proportions(table(mpg$cyl))
```

**3. Sum the proportions: cumsum()**
```{r, echo=TRUE}
cumsum(proportions(table(mpg$cyl)))
```

::: notes

I like analyzing the cylinders variable because it is a good example of a number that is actually the level of an ordinal variable

- We can order these levels from lowest to highest, BUT

- A mean value of 5.9 doesn't mean the typical car has 5.9 cylinders, that's not a thing!

<br>

When analyzing an ordinal variable adding the cumulative proportion can help you identify the median and to describe the distribution

- **What is the median number of cylinders in this dataset?**

- ("6" is where the proportion crosses 50%)

<br>

**Any questions on the functions you need to calculate descriptive statsitics on nominal or ordinal variables?**

<br>

**SLIDE**: As an intro to our interval level variables let's go back to our textbook exercises!

:::



## Exercise 5: Interval-Level Variables {background-image="Images/background-data_blue_v4.png" .center}

<br>

|Statistic|Mike Pence|Tim Kaine|
|:--------|:--------:|:-------:|
|Mean|48.2|46.0|
|Standard deviation|29.4|25.9|
|Mode|50|50|
|25th percentile|30|30|
|50th percentile (median)|50|50|
|75th percentile|70|60|

::: notes

Exercise 5 asks you to evaluate some survey data from the American National Election Survey (ANES)

- The cool part of this exercise is in trying to help you see how summary statistics allow you to "see" the whole distirbution without having to look at thousands of individual responses!

- Let's run through these questions

<br>

**Part A: Why does the Tim Kane feeling thermometer have a negative skew?**

- Skewness is a measure of symmetry: The more skewed the distribution, the less symmetrical it is. 

- Negative skew: those with a skinnier left-hand tail

- (Answer: The mean is lower than the median, indicating negative skew)

<br>

**Part B: Does the mean of the Mike Pence thermometer provide an accurate measure of central tendency?**

- (No, the SD is huge and the range of responses is wide according to the percentiles)

<br>

**Part C: Do Mike Pence’s ratings have a greater amount of variation than Tim Kane’s ratings?**

- (Yes! Mike Pence’s standard deviation is greater than Tim Kaine’s)

<br>

**Part D: Would a respondent who rated Mike Pence at 58 have a mean-centered score of about 10?**

- (Yes. Mean-centered score = 58 − 48.2 = 9.8 ≈ 10.)

<br>

**What is the value of knowing that a rating of 58 is a mean-centered value of 10?**

- (It helps us see how much more or less than average someone feels about Mike Pence!)

- A 58 is someone who likes Pence 10 points more than average!

- Sometimes we want to know about absolute ratings (e.g. a 58 on a 100 point scale) and sometimes we want to know about relative position (e.g. 10 points more positive than the average)

<br>

**What questions do you have about these tools at a conceptual level?**

- **Are we clear on the intuitions underpinning mean, median, SD and percentiles?**

<br>

**SLIDE**: Let's shift from intuitions to formulas

<br>

**Notes**

*If they ask about percentiles* 

- The most common definition of a percentile is a number where a certain percentage of scores fall below that number. 
- In statistics, a k-th percentile (percentile score or centile) is a score below which a given percentage k of scores in its frequency distribution falls (exclusive definition) or a score at or below which a given percentage falls (inclusive definition).

*If they ask about Std Dev*: 

- Hopefully building visualizations next week will help make this concept clearer! 
- Long story short, a measure of how far each data point is from the average...

:::



## Exercise 6: Interval-Level Variables {background-image="Images/background-data_blue_v4.png" .center .smaller}

<br>

```{r}
d2 <- tibble(
  Respondent = 1:7,
  Opinion = c(0,6,8,10,12,14,20)
) |>
  mutate(
    Deviation = Opinion - mean(Opinion),
    Squared = Deviation^2
  )

var1 <- sum(d2$Squared)/(nrow(d2)-1)
sd1 <- sqrt(var1)

d2 |>
  kable(digits = 1, align = "c") |>
  kableExtra::kable_styling(font_size = 30)
```

Mean (Opinion) = 10

Sample Variance = 40

Sample Standard Deviation &#8776; 6.32

::: notes

Here's the completed table.

- **Did everybody get these results?**

<br>

**What questions do you have about the formulas for mean, sample variance and sample standard deviation?**

<br>

Mean = sum(x) / length(x)

Deviation = Opinion Score - mean(Opinion Score)

Sample Variance = Deviation^2 / (n-1)

Sample SD = sqrt(Sample Variance)

![](Images/04-1-Std_Dev_Formula.svg){.absolute width="300"}

<br>

**SLIDE**: I didn't ask you to calculate the standardized scores but let's briefly mention them

:::




## Exercise 6: Interval-Level Variables {background-image="Images/background-data_blue_v4.png" .center .smaller}

<br>

```{r}
d2 |>
  select(-Squared) |>
  mutate(
    SD = sd1,
    Standardized = (Opinion - mean(Opinion))/sd1
  ) |>
  kable(digits = 1, align = "c") |>
  kableExtra::kable_styling(font_size = 30)
```

$$ \text{Standardized Scores (z-scores)} = \frac{(x - \mu)}{\sigma} $$

::: notes

In Exercise 5 you were asked to calculate a mean-centered difference

- That gives us a sense of the relative position of a value to the mean

- Giving that difference meaning in real-world terms requires understanding the scale of the original variable, and

- It cannot be compared to the differences from other scores

<br>

A different, and typically much better, approach is to convert a value into a z-score or standardized score

- Just like before you take each value and subtract the mean but now you divide the result by the standard deviation

- I've done that in the table here

- -10/6.2 is approximately -1.6

<br>

The standardized score tells you how many standard deviations away from the mean is this respondent's value

- This means standardized scores can all be compared across different measures!

- I don't want you to stress this one, but wanted you to see what the rest of the exercise was looking for.

- The usefulness of this as a measure will be made clearer next week!

<br>

**SLIDE**: BOTTOM LINE, don't forget the quote from the great Von Neumann!

:::




## {background-image="Images/background-data_blue_v4.png" .center}

![](Images/01_2-quote-von-neumann.jpg){style="display: block; margin: 0 auto"}

::: notes

I have never come across a quote that spoke more to my experience of being a social scientist.

- I promise you that IF you practice these concepts and tools it will just start to make sense over time!

<br>

So, hang in there this semester and embrace the journey.

<br>

**SLIDE**: Let's use R to calculate these descriptive statistics

:::



## {background-image="Images/background-data_blue_v4.png" .center}

::: {.r-fit-text}
**If you are analyzing an interval-level variable:**
:::

<br>

**1. Use summary() for a selection of descriptive stats**
```{r, echo=TRUE}
summary(mpg$cty)
```

**2. Use sd() for the standard deviation**
```{r, echo=TRUE}
sd(mpg$cty)
```

**3. You can also access the individual stats directly with:**

- mean(), median(), min(), max(), quantile()

::: notes

*Explain the code*

<br>

**Everybody got the code written down and working?**

<br>

**SLIDE**: The code we've used today

:::



## {background-image="Images/background-data_blue_v4.png" .center}

::: {.r-fit-text}
**Univariate Analyses: Descriptive Statistics**
:::

<br>

```{r, echo=TRUE, eval=FALSE}
# Tools for describing a nominal variable:
# Frequency table (counts and/or proportions)

# Tools for describing an ordinal variable:
# Frequency table (counts, proportions and/or cumulative proportions)

# Tools for describing an interval-level variable:
# Mean
# Median
# Standard deviation
# The range (minimum to maximum)
# Percentiles
# The interquartile range (25th to 75th percentile)
```

::: notes

**Ok, how are we doing with these tools?**

- **Any questions before we get to the practice work?**

<br>

**SLIDE**: For next class

:::



## {background-image="Images/background-data_blue_v4.png" .smaller}

1. What proportion of US presidents since 1953 have been Republicans? (Built-in Data: presidential, Variable: party)

2.  Why are the mean and median total populations in the midwest so different from each other? (Built-in Data: midwest, Variable: poptotal)

3. How significant is the problem of poverty in the US midwest? (Built-in Data: midwest, Variables: percbelowpoverty, percchildbelowpovert)

4.  How many hours per day do you have to sleep to sleep longer than 75% of studied mammals? (Built-in Data: msleep, Variable: sleep_total)

5.  Which mammal sleeps the least and which the most? (Built-in Data: msleep, Variable: sleep_total)

6. What is the median number of carburetors in the `mtcars` dataset? (Built-in Data: mtcars, Variable: carb) 

7. How much better fuel economy do cars get when driving on the highway versus driving in the city? Your answer must be clear and must defend your choice of which statistics you have chosen to focus on. (Built-in Data: mpg, Variables: cty, hwy)

::: notes

Assignment for next class to be submitted on Canvas

- For each I want your answer AND the code you used to generate it!

<br>

All these datasets are available from the tidyverse package so make sure to load library(tidyverse) before you start!

:::