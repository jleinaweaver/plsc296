---
format: revealjs
---

# Today's Agenda {background-image="Images/background-data_blue_v4.png"}

```{r}
library(tidyverse)
library(readxl)
library(kableExtra)
library(modelsummary)
```

<br>

::: {.r-fit-text}

**All Measurement Includes Uncertainty**

- Useful survey data is REALLY hard to generate

:::

<br>

::: r-stack
Justin Leinaweaver (Spring 2026)
:::

::: notes
Prep for Class

1. Review Canvas submissions

2. Be ready to publish the blank IDEA survey on Canvas during class

3. Be ready to make the Posit Cloud project public during class

<br>

**SLIDE**: Refreshing last class

:::



## Freedom in the World 2025 {background-image="Images/background-data_blue_v4.png" .center}

![](Images/02_1-Freedom_House_Website.png){style="display: block; margin: 0 auto"}

::: notes

**What were your takeaways from exploring the Freedom House Freedom in the World report?**

<br>

**When would you recommend Freedom House data to someone interested in exploring global freedom?**

- **What kinds of questions can FH answer and what can't it tell us in this area?**

<br>

**SLIDE**: Today we continue our exploration of measurement and uncertainty by looking at surveys as tools for gathering data

:::



## Fowler (2014) {background-image="Images/background-data_blue_v4.png" .center}

<br>

**Fundamental Premises of Survey Research:**

::: {.incremental}

1. You can use a sample to represent a population, and

2. You can design a survey with responses that "accurately describe characteristics of the respondents"

:::
::: notes

Essentially every survey that has ever been run begins from these two assumptions

<br>

**REVEAL**

The first is the assumption that running a survey for SOME people from a target population can tell us something ALL the people in that population

- e.g. A survey of 1,500 Americans to represent the views of 330 million Americans

<br>

Survey sampling is REALLY, REALLY hard and almost no one is able to do this well today for large populations

- Fowler tells us that if you do this badly you are adding "error associated with who answers"

<br>

**REVEAL**

The second assumption is that you can design survey questions that produce answers that actually represent what your survey respondents think

- Fowler tells us that if you do this badly you are adding "error associated with answers"

<br>

This means EVERY survey has at least TWO broad types of error

1. The error that comes from trying to get a good sample, and

2. The error that comes from trying to design good survey questions

<br>

**SLIDE**: Let's dig into each of these a bit more deeply

:::



## {background-image="Images/background-data_blue_v4.png" .center}

### The First Source of Error: The Sample

<br>

How well a sample represents the population depends on:

- The Sampling Frame

- The Sample Size, and

- The Selection Procedure

::: notes

The sampling frame is the set of people that has a chance to be selected for your survey

- The closer your frame is to the entire population, the less error in your survey

- If you want to say something about current Drury students then, ideally, your survey frame would include ALL current drury students 

- Note that the frame doesn't mean you have to ask every Drury student, BUT they all have to have a chance of being included in the survey

- Almost no surveys have survey frames that cover their entire population and every step away from that increases the error in the survey's results

<br>

The sample size is the number of people who actually take your survey

- The more people you ask, the less error in your results (ceteris paribus)

- Think of this most simply as, if you ask everyone in your sample frame then there shouldn't be any error associated with who answers

<br>

The selection procedure is the method by which you decide which people in the population will get your survey

- Ideally you use probability sampling in which every person in the frame has a known, non-zero chance of being selected

- If the people who are selected for your survey are not randomly selected then you are introducing big error into your results

<br>

**Any questions on how these three elements contribute to sampling error in a survey?**

- This is a very serious problem that survey researchers today are grappling with

<br>

**SLIDE**: Let's now jump to the second source of survey error

:::



## {background-image="Images/background-data_blue_v4.png" .center .smaller}

### The Second Source of Error: Designing "Good" Surveys

<br>

:::: {.columns}

::: {.column width="50%"}
**Reliability Problems**

- Inadequate wording
- Incomplete wording
- Poor wording
- Poorly defined terms
- Avoid multiple questions
- Dealing with "Don't know"
- Provide respondent with acceptable answer options

:::

::: {.column width="50%"}
**Validity Problems**

- Ensure respondents understand the question the same way
- Consider lack of knowledge
- Consider social desirability
- Avoid problematic scales
:::

::::

::: notes

Fowler's chapter 6 offers a ton of specific advice for minimizing the second source of error

- e.g. designing questions and surveys that produce results that actually reflect the beliefs of the respondents

<br>

In a moment we'll work to apply this material to the TRIP survey, but first:

- **Any questions on any of these categories or the examples in the chapter?**

<br>

I should say this is not an exhaustive list of the ways survey research can go wrong

- One of my favorite, and most concerning problems, relates to the ordering of the questions in a survey

- Let' say you're running an election survey to measure Trump's approval: 

- Survey option 1: Starts with a series of questions to gauge respondent opinions about the violence of ICE agents against Americans and then asks the Trump approval question
    
- Survey option 2: Ask a series of well designed questions about to gauge respondent opinions about the president cutting taxes and supporting the protestors in Iran and then asks the Trump approval question
    
- Clearly the results of these two surveys, even if given to the exact same sample, will be quite different (recency bias and problem framing effects)

- And yet! Approval #s are reported WITHOUT this CRUCIAL context!

<br>

The takeaway here is that I hope I have flagged for you a bunch of ways all surveys tend to go wrong

- Survey research is hard to do well.

<br>

Ok, I wanted to give you a good, high-quality academic quality survey we can practice evaluating

- **SLIDE**: And that brought me to the TRIP surveys

:::



## {background-image="Images/background-data_blue_v4.png" .center}

![](Images/02_2-TRIP.png){style="display: block; margin: 0 auto"}

::: notes

The TRIP lab at William & Mary has been running and analyzing surveys for the last 20 years

- Their aim has been to "'bridge the gap' between policymakers and scholars in IR to solve the 21st century’s most pressing foreign policy problems

- In practice, they send out surveys on topics of current importance to panels of area experts

<br>

The survey researchers working at TRIP are top-class

- And I think you'll see that even highly skilled survey researchers are forced to make compromises that introduce error in the results

- What I think we'll see is that they are willing to make sacrifices on some elements in order to minimize the error on the parts they caree the most about

<br>

For today I asked you to review their 22 Snap Poll that focused on "a range of global affairs topics, including President Trump’s first 100 days in office."

<br>

*Split class into small groups (groups of 3-4)*

- Sit with your group

<br>

**SLIDE**: Let's dig in!

:::



## Error Associated with Who Answers {background-image="Images/background-data_blue_v4.png" .center}

:::: {.columns}

::: {.column width="50%"}
![](Images/02_2-TRIP_22_Cover.png)
:::

::: {.column width="50%"}

<br>

<br>

Evaluate the:

- Sampling Frame

- Sample Size, and

- Selection Procedure
:::

::::

::: notes

Groups, let's start by evaluating the error associated with who answers the survey

- Focus on the "methodology" (p2) and the "Sample vs. Population Comparison" (p3)

- **Get ready to report back, how much uncertainty is there in there sample if the aim is to reflect expert opinion on these issues?**

<br>

*REPORT BACK and DISCUSS*

<br>

**SLIDE**: Now let's talk evaluate the snap poll for the second source of error

:::



## Error Associated with the Answers {background-image="Images/background-data_blue_v4.png" .center .smaller}

<br>

:::: {.columns}

::: {.column width="33%"}
![](Images/02_2-TRIP_22_Cover.png)
:::

::: {.column width="33%"}
**Reliability Problems**

- Inadequate wording
- Incomplete wording
- Poor wording
- Poorly defined terms
- Avoid multiple questions
- Dealing with "Don't know"
- Provide respondent with acceptable answer options

:::

::: {.column width="33%"}

**Validity Problems**

- Ensure respondents understand the question the same way
- Consider lack of knowledge
- Consider social desirability
- Avoid problematic scales

:::

::::

::: notes

Groups, now evaluate the error associated with the answers in the survey

- Let's highlight the survey questions we think are highly valid and reliable AND the questions we think might not be!

<br>

*REPORT BACK and DISCUSS*

- **For the questions with high error, how does this influence how you interpret the results?**

<br>

**SLIDE**: Let's visualize the results from this survey!

:::



## TRIP Snap Poll 22 Results {background-image="Images/background-data_blue_v4.png" .center}

![](Images/02_2-TRIP_SP_2026_Jan_15.png){style="display: block; margin: 0 auto"}

::: notes

*Two Options*

1. Use the SNAP Poll Dashboard to visualize the tables in the report, OR

2. Open the project on posit cloud and make some pictures!

<br>

Everybody open up our new project on the Posit Cloud!

- The TRIP team was kind enough to share their survey results for this poll with us

- HOWEVER, they have randomized the data to protect the anonymity of the survey respondents

- That means all of the data is included in each variable but you can't study relationships between the variables

- For our purposes today that's totally fine

<br>

The code I've already included in the R file will load the data and make our first table and bar plot

- Try it!

<br>

**Which questions do you want to visualize?**

- Let's do it!

<br>

**For this survey, which statistics did you find most useful for understanding the results?**

- **Did you prefer the tables or the visualizations? Why?**

<br>

*if time remains*: **SLIDE**: Evaluate the IDEA form

*if time is up*: **SLIDE x 2**: Assignment for next class

:::



## {background-image="Images/background-data_blue_v4.png" .center}

:::: {.columns}

::: {.column width="50%"}
![](Images/02_2-IDEA_Page1.png)
:::

::: {.column width="50%"}

<br>

<br>

**Error 1: Who Answers**

- Sampling frame, sample size, selection procedure

**Error 2: The Answers**

- Survey and question design choices

:::

::::

::: notes

Alright my friends, I have posted the current IDEA course evaluation questions on our Canvas Modules page

- I would like us to take a few minutes evaluating the tool that Drury, and almost all universities, use to evaluate your experiences at college

<br>

**So, what do you think?**

- **How much error in the samples?**

- **How much error in the questions?**

<br>

**SLIDE**: For next class

:::




## For Next Class {background-image="Images/background-data_blue_v4.png" .center}

<br>

Select **THREE** variables from the World Bank's World Development Indicators (WDI) database

- What would you be interested in exploring?

- Details on Canvas


::: notes

Next week I want each of you to practice evaluating a measurement from the World Bank's extensive database of international metrics

<br>

The details are on Canvas

- Look for variables you would be interested in exploring further!

- There are four variables you CANNOT pick

- No overlap in class! First-come, first-served

<br>

**Any questions on our material from today or the assignment?**

<br>

Canvas DISCUSSION: Explore the WDI

Explore the data options in the World Bank's World Development Indicators (WDI) database (https://datatopics.worldbank.org/world-development-indicators/).

Select THREE variables you think look interesting and would like to explore further. 

Do not submit variables already selected by others in class.
IMPORTANT NOTE: You may not select measles immunizations (%), birth rate, death rate or GDP per capita because we will explore them later in the semester

For **each** variable:

- What is the variable?
- Why are you interested in exploring it?
- What is the original source for this variable? (e.g. where does the World Bank get it?)




:::
